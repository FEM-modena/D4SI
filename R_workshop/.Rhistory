html_text(names)
names <- str_trim(names)
names<- names[grep("Sta|Math|sta|math", names)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names <- str_trim(names)
names<- names[grep("Sta|Math|sta|math", names)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Sta|Math|sta|math", names)]
length(unique(names))
names<- names[grep("Stat|Math", names)]
length(unique(names))
names<- names[grep("Stat|Math", names, ignore.case)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Stat|Math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stat|Math", names, ignore.case = FALSE)]
length(unique(names))
names<- names[grep("Stat|Math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stati||Math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stati", names, ignore.case = TRUE)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("stati||math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stati||Math", names, ignore.case = FALSE)]
length(unique(names))
names<- names[grep("Stati||Math", names, ignore.case = TRUE)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Stati||Math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stati||Math", names)]
length(unique(names))
names<- names[grep("Stat||Math", names)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Stat||Math", names)]
length(unique(names))
names<- grep("Stati||Math", names, value = TRUE, ignore.case = TRUE)
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- grep("Stati||Math", names, value = TRUE, ignore.case = TRUE)
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
solution<- grep("Stati||Math", names, value = TRUE, ignore.case = TRUE)
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Statistics|Mathematics|Biostatistics", names)]
length(unique(names))
names<- names[grep("Stati|Math", names)]
length(unique(names))
names<- names[grep("Stati|Math", names, ignore.case = T)]
length(unique(names))
names<- names[grep("Stati|Math", names, ignore.case = TRUE)]
length(unique(names))
str_view_all(pattern = "Stati|Math", string = names, ignore.case(names))
str_view_all(pattern = "Stati|Math", string = names)
str_view_all(pattern = "Stati|Math", string = names, ignore.case = TRUE)
str_view_all(pattern = "Stati|Math|stat", string = names)
names<- names[grep("Stati|Math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stat|Math", names, ignore.case = TRUE)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Stat|Math", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("Stat|Math", names)]
length(unique(names))
names<- names[grep("Stat|Math|stati|math", names)]
length(unique(names))
names <- data.frame(sort(table(names)))
names <- data.frame((table(names)))
names <- data.frame(sort(table(names)))
names<- names[grep("Stati|Math", names)]
length(unique(names))
names<- names[grep("Stati", names)]
length(unique(names))
names<- names[grep("Stat", names)]
length(unique(names))
test<- grep(pattern = "Stat||Math", string = names, value = TRUE, ignore.case = TRUE)
names<- grep(pattern = "Stat||Math", string = names, value = TRUE, ignore.case = TRUE)
names<- grep(pattern = "Stat||Math", names, value = TRUE, ignore.case = TRUE)
length(unique(names))
names<- grep(pattern = "Stat|Math", names, value = TRUE, ignore.case = TRUE)
length(unique(names))
names<- grep(pattern = "Stat|Math", names, ignore.case = TRUE)
length(unique(names))
names <- names[!str_detect(names, "Stat||Math")]
length(unique(names))
names <- names[grep(names, "Stat||Math")]
names <- names[grep("Stat||Math", names)]
length(unique(names))
names <- grep("Stat||Math", names)
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names <- grep("Stat||Math", names)
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("Statistics|Mathematics|Biostatistics", names, ignore.case = TRUE)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("statistics|mathematics|biostatistics|mathematical", names, ignore.case = TRUE)]
length(unique(names))
str_view_all("statistics|mathematics|biostatistics|mathematical", names)
str_view_all(names,"statistics|mathematics|biostatistics|mathematical")
str_view_all(names,"stat|math")
str_view_all(names,"stat")
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
str_view_all(names,"stat")
str_view_all(names,"stat|math")
names<- names[grep("statistics|mathematics", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("statistics|mathematics|mathematical", names, ignore.case = TRUE)]
length(unique(names))
names<- names[grep("statistics|mathematics|mathematical|biostatistics", names, ignore.case = TRUE)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("stati|math", names, ignore.case = TRUE)]
length(unique(names))
url <- "https://www.jstatsoft.org/about/editorialTeam"
url_parsed <- read_html(url)
css <- "#group a"
html_nodes(url_parsed, css = css) %>% html_text
css_full_lines <- "#group li"
html_nodes(url_parsed, css = css_full_lines) %>%  html_text
names <- html_nodes(url_parsed, css = css_full_lines)
html_text(names)
names<- names[grep("stati|math", names, ignore.case = TRUE)]
length(unique(names))
install.packages("knitr")
library(knitr) #
library(tidyverse)
library(stringr)
library(rvest)
devtools::install_github("JustinMShea/wooldridge")
devtools::install_github("JustinMShea/wooldridge@dev", build_vignettes = TRUE)
devtools::install_github("JustinMShea/wooldridge@dev")
library(wooldridge)
install.packages("packages.r")
install.packages("htmlwidgets")
install.packages("dygraphs")
install.packages("flexdashboard")
install.packages("DT")
install.packages("shiny")
install.packages("plotly")
library(htmlwidgets) #
library(dygraphs) #
library(flexdashboard) #
library(DT) #
library(shiny) #
library(plotly) #
library(ggplot2)
runApp('Desktop/1.Data_Management_R/R_exercise/week_11/App-1')
runApp('Desktop/1.Data_Management_R/R_exercise/week_11/App-1')
runApp('Desktop/1.Data_Management_R/R_exercise/week_11/App-1')
flights
library(flexdashboard)
library(shinydashboard)
library(dplyr)
library(dbplyr)
library(purrr)
library(shiny)
library(highcharter)
library(DT)
library(htmltools)
library(nycflights13)
flights
?carrier
?flights
airlines
webshot::install_phantomjs()
git remote add origin https://github.com/billokan/Final_Project_Data_Management.git
git push -u origin master
install.packages("git")
library("git2r", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
git remote add origin https://github.com/billokan/Final_Project_Data_Management.git
git push -u origin master
install.packages("git2r")
install.packages("githubinstall")
library("githubinstall", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("git2r", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
git remote add origin https://github.com/billokan/Final_Project_Data_Management.git
git push -u origin master
git remote add origin https://github.com/billokan/Final_Project_Data_Management.git
git push --set-upstream origin master
cat .git/config
install.packages(c("backports", "curl", "digest", "dotCall64", "foreach", "iterators", "reshape2", "yaml"))
githubinstall::gh_install_packages()
git
# overview of packages:
browseURL("http://cran.r-project.org/web/packages/")
# - packages are installed once (usually after downloading them from CRAN)
# - installing packages in RStudio is straightforward
# - updating packages is straightforward, too
# - we can also use the console to install packages
install.packages("readr")
# packages are loaded for every session
library(readr)
# how to get more info about package?
# - browse CRAN online!
browseURL("https://cran.rstudio.com/web/packages/readr/index.html")
# importing rectangular spreadsheet data
library(readr)
library(dplyr)
install.packages("wooldridge")
library(dplyr)
### let's try it out with an interesting dataset!
library(nycflights13)
?flights
head(flights)
nrow(flights)
table(flights$origin)
source('~/Desktop/Script_R_Lab_5.R', echo=TRUE)
source('~/Desktop/Script_R_Lab_5.R', echo=TRUE)
source('~/Desktop/Script_R_Lab_5.R', echo=TRUE)
source('~/Desktop/Script_R_Lab_5.R', echo=TRUE)
# roll a dice using R's random number generator
runif()
# random draw of 10 values from a uniform distribution
dice <- runif(n = 10, min = 1, max = 7)
dice
# random draw of 10 values from a uniform distribution
dice2 <- runif(n = 10, min = 1, max = 7)
# 1st draw
dice
# 2nd draw
dice2
# set random number generator
set.seed(123)
# random draw of 10 values from a uniform distribution
dice <- runif(n = 10, min = 1, max = 7)
dice
# if you do more than once the numbers will change
# set random number generator
set.seed(123)
# 1st random draw of 10 values from a uniform distribution
dice <- runif(n = 10, min = 1, max = 7)
dice
# 2nd random draw of 10 values from a uniform distribution
dice2 <- runif(n = 10, min = 1, max = 7)
dice2
# reset random number generator
set.seed(123)
# 3rd random draw of 10 values from a uniform distribution
dice3 <- runif(n = 10, min = 1, max = 7)
dice3
# 4th random draw of 10 values from a uniform distribution
dice4 <- runif(n = 10, min = 1, max = 7)
dice4
# introduce as.integer()
# reset random number generator
set.seed(123)
# random draw of 10 numbers from a uniform distribution with minimum 1 and maximum 7
dice <- runif(10, 1, 7)
# cut off decimals places
dice <- as.integer(dice)
dice
# frequency of dice rolls
table(dice)
# frequency of dice rolls
table(dice)
# compute the mean in our sample and the SD
dice.sum <- dice[1] + dice[2] + dice[3] + dice[4] + dice[5] + dice[6] + dice[7] + dice[8] + dice[9] + dice[10]
dice.mean <- dice.sum / 10
dice.mean
# estimate standard deviation withou using sd() function and don't copy and paste
numerator <- ( (dice[1] - dice.mean)^2 + (dice[2] - dice.mean)^2 + (dice[3] - dice.mean)^2  +
(dice[4] - dice.mean)^2 + (dice[5] - dice.mean)^2 + (dice[6] - dice.mean)^2 +
(dice[7] - dice.mean)^2 + (dice[8] - dice.mean)^2 + (dice[9] - dice.mean)^2 +
(dice[10] - dice.mean)^2 )
std.dev <- sqrt( (numerator / 9) )
std.dev
# try yourself!
# standard error of the sample mean
std.err <- std.dev / sqrt(10)
# t value
t.value <- (4 - 3.5) / std.err
t.value
# try yourself
# compute the variance of the mean
# sample variance
variance <- numerator / 9
# variance of the mean
var.mean <- variance / 10
var.mean
# correct asnwer is 0.31, now compute standard error
# variance of the mean
sqrt(var.mean)
# estimante p value from a t distribution
p.value <- (1 - pt(t.value, df = 9))*2
p.value
# now, we construct interval around our mean estimate
# first we get critical value from the quantile function of t distribution with n-1 DoF
qt(p = 0.975, df = 9)
# lower bound
lb <- dice.mean - qt(p = 0.975, df = 9) * std.err
# upper bound
ub <- dice.mean + qt(p = 0.975, df = 9) * std.err
# confidence interval
lb
ub
# run t test using t.test()
t.test(dice,
mu = 3.5,
conf.level = .95)
#1 Clean everything
rm(list = ls())
#2. Set the random number generator to 1234.
set.seed(1234)
#3. Generate a vector of 100 rolls of a fair dice on your own and show the results in a frequency table.
fair.die <- runif(n = 100, min = 1, max = 7)
fair.die <- as.integer(fair.die)
table(fair.die)
# compute the mean in our sample and the SD
dice.sum <- dice[1] + dice[2] + dice[3] + dice[4] + dice[5] + dice[6] + dice[7] + dice[8] + dice[9] + dice[10]
dice.mean <- dice.sum / 10
# introduce as.integer()
# reset random number generator
set.seed(123)
# random draw of 10 numbers from a uniform distribution with minimum 1 and maximum 7
dice <- runif(10, 1, 7)
# cut off decimals places
dice <- as.integer(dice)
dice
# frequency of dice rolls
table(dice)
# compute the mean in our sample and the SD
dice.sum <- dice[1] + dice[2] + dice[3] + dice[4] + dice[5] + dice[6] + dice[7] + dice[8] + dice[9] + dice[10]
dice.mean <- dice.sum / 10
dice.mean
# estimate standard deviation withou using sd() function and don't copy and paste
numerator <- ( (dice[1] - dice.mean)^2 + (dice[2] - dice.mean)^2 + (dice[3] - dice.mean)^2  +
(dice[4] - dice.mean)^2 + (dice[5] - dice.mean)^2 + (dice[6] - dice.mean)^2 +
(dice[7] - dice.mean)^2 + (dice[8] - dice.mean)^2 + (dice[9] - dice.mean)^2 +
(dice[10] - dice.mean)^2 )
std.dev <- sqrt( (numerator / 9) )
std.dev
sd(dice.sum)
library(foreign)
library(texreg)
# load dataset in Stata format from online source
world_data <- read.dta("https://github.com/philippbroniecki/statistics1/raw/master/data/qog_std_cs_jan15.dta")
names(world_data)[which(names(world_data) == "cname")] <- "country"
names(world_data)[which(names(world_data) == "wbgi_pse")] <- "political_stability"
names(world_data)[which(names(world_data) == "lp_lat_abst")] <- "latitude"
names(world_data)[which(names(world_data) == "dr_ig")] <- "globalization"
names(world_data)[which(names(world_data) == "chga_demo")] <- "democracy"
names(world_data)[which(names(world_data) == "ti_cpi")] <- "institutions_quality"
keep <- c("country", "political_stability", "latitude", "globalization","democracy", "institutions_quality")
world_data <- world_data[, keep]
head(world_data)
summary(world_data)
world_data <- world_data[ !is.na(world_data$latitude), ]
world_data <- world_data[ !is.na(world_data$globalization) ]
library(dplyr)
survey <- read.csv("Downloads/tweetdata.csv")
View(survey)
str(survey$educ)
summary(survey$educ)
summary(survey$partyid)
install.packages(c("anytime", "babynames", "backports", "BH", "broom", "ca", "callr", "caTools", "class", "classInt", "cli", "clipr", "coda", "codetools", "colorspace", "countrycode", "cowplot", "curl", "data.table", "dbplyr", "devtools", "digest", "dplyr", "DT", "e1071", "eeptools", "evaluate", "fansi", "forcats", "future", "future.apply", "geojson", "geojsonlint", "ggforce", "ggmap", "ggplot2", "ggthemes", "git2r", "globals", "haven", "highcharter", "htmlwidgets", "httpuv", "httr", "hunspell", "igraph", "interactionTest", "irlba", "ISOcodes", "jqr", "jsonlite", "knitr", "koRpus", "later", "lattice", "leaflet", "lme4", "maptools", "mapview", "markdown", "MASS", "Matrix", "memisc", "mgcv", "mime", "modelr", "NCmisc", "network", "nloptr", "NLP", "openssl", "packrat", "pbapply", "pdftools", "pillar", "plm", "prediction", "processx", "ps", "psych", "purrr", "quanteda", "R.utils", "R6", "RApiDatetime", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "readr", "readxl", "repr", "reprex", "reshape", "reticulate", "rgdal", "rgeos", "RgoogleMaps", "RJSONIO", "rlang", "rmarkdown", "rsconnect", "RSelenium", "rstudioapi", "rtweet", "sf", "shiny", "shinydashboard", "slam", "SnowballC", "spacyr", "spam", "spData", "stars", "stringi", "stringr", "survival", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tm", "tseries", "TTR", "tweenr", "units", "V8", "webshot", "wooldridge", "writexl", "xfun", "XML", "xtable", "xts", "zip", "zoo"))
install.packages(c("assertthat", "callr", "cli", "colorspace", "crul", "devtools", "e1071", "eeptools", "fs", "ggforce", "git2r", "glue", "gtable", "highr", "httpuv", "lazyeval", "Matrix", "memisc", "mgcv", "openssl", "pdftools", "pkgbuild", "polyclip", "processx", "purrr", "quantmod", "Rcpp", "RcppArmadillo", "readxl", "rgdal", "rlang", "rmarkdown", "rstudioapi", "stringi", "tibble", "tinytex", "V8", "zip", "zoo"))
y
install.packages(c("fs", "git2r", "Matrix", "mgcv", "openssl", "RcppArmadillo", "rlang", "zoo"))
install.packages(c("fs", "git2r", "Matrix", "mgcv", "openssl", "RcppArmadillo", "rlang", "zoo"))
install.packages(c("fs", "git2r", "Matrix", "mgcv", "openssl", "RcppArmadillo", "rlang", "zoo"))
install.packages(c("anytime", "backports", "bdsmatrix", "BH", "bibtex", "bit", "boot", "broom", "ca", "callr", "class", "classInt", "cli", "cluster", "corpus", "countrycode", "covr", "crosstalk", "crul", "curl", "data.table", "DBI", "dbplyr", "devtools", "digest", "dplyr", "DT", "e1071", "fansi", "farver", "fields", "forcats", "foreach", "fs", "future", "future.apply", "gdalUtils", "gender", "geojsonio", "geojsonlint", "geosphere", "ggplot2", "gh", "git2r", "globals", "glue", "gtools", "haven", "hexbin", "hms", "htmltools", "htmlwidgets", "httpcode", "httpuv", "igraph", "interplot", "janitor", "jpeg", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "leafem", "leaflet", "lifecycle", "listenv", "lme4", "lmtest", "lubridate", "mapproj", "maptools", "markdown", "MASS", "Matrix", "maxLik", "mgcv", "mime", "miscTools", "mnormt", "modelr", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "patchwork", "pdftools", "pillar", "pkgbuild", "PKI", "plm", "plyr", "prettyunits", "processx", "promises", "protolite", "ps", "psych", "purrr", "quadprog", "quantmod", "R.methodsS3", "R.oo", "R.utils", "R6", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "Rdpack", "remotes", "reshape2", "reticulate", "rex", "rgeos", "RgoogleMaps", "rJava", "RJDBC", "RJSONIO", "rlang", "rmarkdown", "roxygen2", "rpart", "rsconnect", "RSelenium", "RSpectra", "rstudioapi", "Rttf2pt1", "rversions", "rvest", "satellite", "scales", "selectr", "sf", "shiny", "slam", "sna", "SnowballC", "sp", "spacyr", "spam", "spatial", "spData", "spiderbar", "stars", "stopwords", "stringi", "survival", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "tm", "tseries", "TTR", "units", "urltools", "usethis", "uuid", "V8", "vcd", "vctrs", "wdman", "webshot", "withr", "writexl", "xfun", "xlsx", "XML", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("anytime", "backports", "bdsmatrix", "bibtex", "bit", "broom", "callr", "class", "classInt", "cluster", "corpus", "covr", "curl", "data.table", "dbplyr", "devtools", "digest", "dplyr", "e1071", "fansi", "farver", "fields", "fs", "geosphere", "git2r", "glue", "gtools", "haven", "hexbin", "hms", "htmltools", "httpuv", "igraph", "janitor", "jpeg", "jsonlite", "KernSmooth", "later", "lattice", "lmtest", "lubridate", "mapproj", "maptools", "markdown", "MASS", "Matrix", "mgcv", "mime", "mnormt", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "pdftools", "PKI", "plyr", "processx", "promises", "protolite", "ps", "purrr", "quadprog", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "reshape2", "reticulate", "rgeos", "rJava", "RJDBC", "RJSONIO", "rlang", "roxygen2", "rpart", "RSpectra", "Rttf2pt1", "satellite", "sf", "slam", "SnowballC", "sp", "spacyr", "spam", "spatial", "spiderbar", "stringi", "survival", "testthat", "tibble", "tidyr", "tidyselect", "tm", "tseries", "TTR", "units", "urltools", "usethis", "uuid", "V8", "vctrs", "writexl", "xlsx", "XML", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages("survival")
library(readr)
X2020_Cities_Disclosing_to_CDP <- read_csv("Downloads/Cities/Cities Disclosing/2020_Cities_Disclosing_to_CDP.csv")
View(X2020_Cities_Disclosing_to_CDP)
library(readr)
X2020_Full_Cities_Dataset <- read_csv("Downloads/Cities/Cities Responses/2020_Full_Cities_Dataset.csv")
View(X2020_Full_Cities_Dataset)
View(X2020_Full_Cities_Dataset)
X2020_Full_Cities_Dataset %>%
filter(country == 'Italy')
library(dplyr)
library(tidyr)
library(rvest)
library(lubridate)
library(tidyverse)
library(ggplot2)
X2020_Full_Cities_Dataset %>%
filter(country == 'Italy')
View(X2020_Full_Cities_Dataset)
X2020_Full_Cities_Dataset %>%
filter(Country == 'Italy')
library(readr)
X2018_Full_Climate_Change_Dataset <- read_csv("Downloads/2018_Full_Climate_Change_Dataset.csv")
View(X2018_Full_Climate_Change_Dataset)
X2018_Full_Climate_Change_Dataset %>%
count(unique(organization))
X2018_Full_Climate_Change_Dataset %>%
sum(unique(organization))
unique(X2018_Full_Climate_Change_Dataset$organization)
setwd("~/Desktop/GitHub/D4SI/R_workshop")
library(knitr)
library(methods)
library(knitr)
library(methods)
